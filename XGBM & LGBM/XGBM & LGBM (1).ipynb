{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07dcb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26953530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "try:\n",
    "    df_train = pd.read_csv('Titanic_train.csv')\n",
    "    df_test = pd.read_csv('Titanic_test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find the datasets. Please ensure the file paths are correct.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc95915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Missing values in testing data:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"Missing values in testing data:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95699d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_train['Age'] = imputer.fit_transform(df_train[['Age']])\n",
    "df_test['Age'] = imputer.transform(df_test[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4507d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
    "df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc6d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['Cabin'], inplace=True)\n",
    "df_test.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfc764af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_train = pd.get_dummies(df_train, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "df_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc882f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the same columns in both datasets\n",
    "for col in df_train.columns:\n",
    "    if col not in df_test.columns:\n",
    "        df_test[col] = 0\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col not in df_train.columns:\n",
    "        df_train[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c209029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to match exactly\n",
    "df_train = df_train[df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f848e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not useful for the model\n",
    "df_train.drop(columns=['Name', 'Ticket'], inplace=True)\n",
    "df_test.drop(columns=['Name', 'Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2010aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "features_to_scale = ['Age', 'Fare']\n",
    "df_train[features_to_scale] = scaler.fit_transform(df_train[features_to_scale])\n",
    "df_test[features_to_scale] = scaler.transform(df_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e97c0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "try:\n",
    "    X_train = df_train.drop(columns=['Survived'])\n",
    "    y_train = df_train['Survived']\n",
    "\n",
    "    X_test = df_test.drop(columns=['Survived'])\n",
    "    y_test = df_test['Survived']\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e} not found in the dataset columns.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a073e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 478\n",
      "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
      "[LightGBM] [Info] Start training from score -0.473288\n"
     ]
    }
   ],
   "source": [
    "# Build predictive models\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e666727",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ecce983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a403dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lgb_results = evaluate_model(y_test, y_pred_lgb)\n",
    "xgb_results = evaluate_model(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f11361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results: Accuracy=0.6626794258373205, Precision=0.0, Recall=0.0, F1-score=0.0\n",
      "XGBoost Results: Accuracy=0.6674641148325359, Precision=0.0, Recall=0.0, F1-score=0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'LightGBM Results: Accuracy={lgb_results[0]}, Precision={lgb_results[1]}, Recall={lgb_results[2]}, F1-score={lgb_results[3]}')\n",
    "print(f'XGBoost Results: Accuracy={xgb_results[0]}, Precision={xgb_results[1]}, Recall={xgb_results[2]}, F1-score={xgb_results[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d768906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
